{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Danio Danio is a ORM for python asyncio world.It is designed to make getting easy and clearly.It builds on python's dataclass and encode's databases Features keep OOM in mind, custom your Field and Model behavior easily type hints any where, no more need to memorize words your field names any more base CRUD operation, transactions, lock and so on signals like before save, after save and so on complex operation like bulk create, upsert, create or update and so on assist model schema migration support MySQL/PostgreSQL/SQLite hints generation install pip install danio Documents Danio Document Glance db = danio.Database( \"mysql://root:letmein@server:3306/test\", maxsize=3, charset=\"utf8mb4\", use_unicode=True, connect_timeout=60, ) @dataclasses.dataclass class User(danio.Model): # auto generated by danio: # --------------------Danio Hints-------------------- # TABLE NAME: user # TABLE IS MIGRATED! ID: typing.ClassVar[danio.Field] # \"id\" serial PRIMARY KEY NOT NULL NAME: typing.ClassVar[danio.Field] # \"name\" varchar(255) NOT NULL AGE: typing.ClassVar[danio.Field] # \"age\" int NOT NULL CREATED_AT: typing.ClassVar[ danio.Field ] # \"created_at\" timestamp without time zone NOT NULL UPDATED_AT: typing.ClassVar[ danio.Field ] # \"updated_at\" timestamp without time zone NOT NULL GENDER: typing.ClassVar[danio.Field] # \"gender\" int NOT NULL # --------------------Danio Hints-------------------- class Gender(enum.Enum): MALE = 0 FEMALE = 1 OTHER = 2 id: typing.Annotated[int, danio.IntField(primary=True, type=\"serial\")] = 0 name: typing.Annotated[str, danio.CharField(comment=\"User name\")] = \"\" age: typing.Annotated[int, danio.IntField] = 0 created_at: typing.Annotated[ datetime.datetime, danio.DateTimeField(type=\"timestamp without time zone\", comment=\"when created\"), ] = dataclasses.field(default_factory=datetime.datetime.now) updated_at: typing.Annotated[ datetime.datetime, danio.DateTimeField(type=\"timestamp without time zone\", comment=\"when updated\"), ] = dataclasses.field(default_factory=datetime.datetime.now) gender: typing.Annotated[Gender, danio.IntField(enum=Gender)] = Gender.MALE async def before_create(self, validate=True): await super().before_create(validate=True) async def before_update(self, validate=True): self.updated_at = datetime.datetime.now() await super().before_update(validate=True) async def validate(self): await super().validate() if not self.name: raise danio.ValidateException(\"Empty name!\") @classmethod def get_database( cls, operation: danio.Operation, table: str, *args, **kwargs ) -> danio.Database: return db # base CRUD user = await User(name=\"batman\").save() user = await User.where(User.NAME == \"batman\").fetch_one() user.gender = User.Gender.MALE await user.save() await user.delete() # sql chain await User.where(User.NAME != \"\").limit(10).fetch_all() # multi where condition await User.where(User.ID != 1, User.NAME != \"\").fetch_all() await User.where(User.ID != 1).where(User.NAME != \"\").fetch_all() await User.where(User.ID <= 10, User.ID >= 20, is_and=False).fetch_all() # complicated expression await User.where(User.ID == 1).update(age=(User.AGE + 1) / (User.AGE / 12) - 2) await User.where((User.AGE + 1) == 3).fetch_all() # complicated sql operation await User.where(User.ID == u.id).update( age=User.AGE.case(User.AGE > 10, 1, default=18).case(User.AGE <= 0, 10) ) created, updated = await UserProfile.upsert( [ dict(id=1, name=\"upsert\"), ], update_fields=[\"name\"], ) # bulk operation await User.bulk_create([User(name=f\"user_{i}\") for i in range(10)]) await User.bulk_update(await User.fetch_all()) await User.bulk_delete(await User.fetch_all()) # shortcut user, created = await User(id=1, name=\"created?\").get_or_create( key_fields=(User.ID,) ) user, created, updated = await User(id=2, name=\"updated?\").create_or_update( key_fields=(User.ID,) )","title":"Introduction"},{"location":"#danio","text":"Danio is a ORM for python asyncio world.It is designed to make getting easy and clearly.It builds on python's dataclass and encode's databases","title":"Danio"},{"location":"#features","text":"keep OOM in mind, custom your Field and Model behavior easily type hints any where, no more need to memorize words your field names any more base CRUD operation, transactions, lock and so on signals like before save, after save and so on complex operation like bulk create, upsert, create or update and so on assist model schema migration support MySQL/PostgreSQL/SQLite hints generation","title":"Features"},{"location":"#install","text":"pip install danio","title":"install"},{"location":"#documents","text":"Danio Document","title":"Documents"},{"location":"#glance","text":"db = danio.Database( \"mysql://root:letmein@server:3306/test\", maxsize=3, charset=\"utf8mb4\", use_unicode=True, connect_timeout=60, ) @dataclasses.dataclass class User(danio.Model): # auto generated by danio: # --------------------Danio Hints-------------------- # TABLE NAME: user # TABLE IS MIGRATED! ID: typing.ClassVar[danio.Field] # \"id\" serial PRIMARY KEY NOT NULL NAME: typing.ClassVar[danio.Field] # \"name\" varchar(255) NOT NULL AGE: typing.ClassVar[danio.Field] # \"age\" int NOT NULL CREATED_AT: typing.ClassVar[ danio.Field ] # \"created_at\" timestamp without time zone NOT NULL UPDATED_AT: typing.ClassVar[ danio.Field ] # \"updated_at\" timestamp without time zone NOT NULL GENDER: typing.ClassVar[danio.Field] # \"gender\" int NOT NULL # --------------------Danio Hints-------------------- class Gender(enum.Enum): MALE = 0 FEMALE = 1 OTHER = 2 id: typing.Annotated[int, danio.IntField(primary=True, type=\"serial\")] = 0 name: typing.Annotated[str, danio.CharField(comment=\"User name\")] = \"\" age: typing.Annotated[int, danio.IntField] = 0 created_at: typing.Annotated[ datetime.datetime, danio.DateTimeField(type=\"timestamp without time zone\", comment=\"when created\"), ] = dataclasses.field(default_factory=datetime.datetime.now) updated_at: typing.Annotated[ datetime.datetime, danio.DateTimeField(type=\"timestamp without time zone\", comment=\"when updated\"), ] = dataclasses.field(default_factory=datetime.datetime.now) gender: typing.Annotated[Gender, danio.IntField(enum=Gender)] = Gender.MALE async def before_create(self, validate=True): await super().before_create(validate=True) async def before_update(self, validate=True): self.updated_at = datetime.datetime.now() await super().before_update(validate=True) async def validate(self): await super().validate() if not self.name: raise danio.ValidateException(\"Empty name!\") @classmethod def get_database( cls, operation: danio.Operation, table: str, *args, **kwargs ) -> danio.Database: return db # base CRUD user = await User(name=\"batman\").save() user = await User.where(User.NAME == \"batman\").fetch_one() user.gender = User.Gender.MALE await user.save() await user.delete() # sql chain await User.where(User.NAME != \"\").limit(10).fetch_all() # multi where condition await User.where(User.ID != 1, User.NAME != \"\").fetch_all() await User.where(User.ID != 1).where(User.NAME != \"\").fetch_all() await User.where(User.ID <= 10, User.ID >= 20, is_and=False).fetch_all() # complicated expression await User.where(User.ID == 1).update(age=(User.AGE + 1) / (User.AGE / 12) - 2) await User.where((User.AGE + 1) == 3).fetch_all() # complicated sql operation await User.where(User.ID == u.id).update( age=User.AGE.case(User.AGE > 10, 1, default=18).case(User.AGE <= 0, 10) ) created, updated = await UserProfile.upsert( [ dict(id=1, name=\"upsert\"), ], update_fields=[\"name\"], ) # bulk operation await User.bulk_create([User(name=f\"user_{i}\") for i in range(10)]) await User.bulk_update(await User.fetch_all()) await User.bulk_delete(await User.fetch_all()) # shortcut user, created = await User(id=1, name=\"created?\").get_or_create( key_fields=(User.ID,) ) user, created, updated = await User(id=2, name=\"updated?\").create_or_update( key_fields=(User.ID,) )","title":"Glance"},{"location":"bulk_queries/","text":"Bulk Queries Optimize database IO performance when operate multi instance or table row data. Bulk Create @classmethod async def bulk_create( cls: typing.Type[MODEL_TV], instances: typing.Sequence[MODEL_TV], fields: typing.Sequence[Field] = (), database: typing.Optional[Database] = None, validate: bool = True, ) -> typing.Sequence[MODEL_TV] This method will insert multi instance to Database in one sql: INSERT TABLE <table name> VALUES (<values>), ...; And all instances will active model signals( before_save and after_save ) eg: users = [User(name=f\"user_{i}\") for i in range(10)] await User.bulk_create(users) For better database performance\uff0cif there are too many instances, consider grouping them and calling bulk_create in sequence. Bulk Update @classmethod async def bulk_update( cls: typing.Type[MODEL_TV], instances: typing.Sequence[MODEL_TV], fields: typing.Sequence[Field] = (), database: typing.Optional[Database] = None, validate: bool = True, ) -> typing.Sequence[MODEL_TV] This method will update all instance by sql case statement, example sql: UPDATE `user` SET `name` = CASE WHEN `id` = <id1> THEN <name1> WHEN `id` = <id2> THEN <name2> WHEN `id` = <id3> THEN <name3> end, WHERE `id` IN ( <id1>, <id2>, <id3>); And all instances will active model signals too. eg: users = await User.where().fetch_all() for u in users: u.name += \"_updated\" await User.bulk_update(users, fields=(User.name, )) Consider grouping instances and calling bulk_update in sequence if instances size is too large. Bulk delete @classmethod async def bulk_delete( cls, instances: typing.Sequence[MODEL_TV], database: typing.Optional[Database] = None, ) -> int This method will delete all instance in database and return deleted count, example sql: DELETE FROM <table> WHERE `id` IN (<id1>, <id2>) And all instances will active model signals too. Upsert @classmethod async def upsert( cls, insert_data: typing.List[typing.Dict[str, typing.Any]], database: typing.Optional[Database] = None, update_fields: typing.Sequence[str] = (), conflict_targets: typing.Sequence[str] = (), ) -> typing.Tuple[bool, bool] This method using insert on duplicate, sql example for MySQL: INSERT INTO <table> (<f1>,<f2>) VALUES (<v1>,<v2>) ON DUPLICATE KEY UPDATE <f2>=VALUES(<f2>); And this method just execute a raw sql, eg: created, updated = await User.upsert( [ dict(id=1, name=\"updated\"), ], update_fields=[\"name\"], ) Difference between Databases For MySQL, updated means the table has been real updated(It will be False if update to original value), but MySQL will only update the first matched unique key if there are many matched conflict unique keys. For PostgreSQL, created and updated will always be true, need explicit conflict_targets . For SQLITE, updated will always be true. Documents: https://dev.mysql.com/doc/refman/5.6/en/insert-on-duplicate.html https://www.sqlite.org/lang_upsert.html https://www.postgresql.org/docs/9.4/plpgsql-control-structures.html#PLPGSQL-ERROR-TRAPPING","title":"Bulk Queries"},{"location":"bulk_queries/#bulk-queries","text":"Optimize database IO performance when operate multi instance or table row data.","title":"Bulk Queries"},{"location":"bulk_queries/#bulk-create","text":"@classmethod async def bulk_create( cls: typing.Type[MODEL_TV], instances: typing.Sequence[MODEL_TV], fields: typing.Sequence[Field] = (), database: typing.Optional[Database] = None, validate: bool = True, ) -> typing.Sequence[MODEL_TV] This method will insert multi instance to Database in one sql: INSERT TABLE <table name> VALUES (<values>), ...; And all instances will active model signals( before_save and after_save ) eg: users = [User(name=f\"user_{i}\") for i in range(10)] await User.bulk_create(users) For better database performance\uff0cif there are too many instances, consider grouping them and calling bulk_create in sequence.","title":"Bulk Create"},{"location":"bulk_queries/#bulk-update","text":"@classmethod async def bulk_update( cls: typing.Type[MODEL_TV], instances: typing.Sequence[MODEL_TV], fields: typing.Sequence[Field] = (), database: typing.Optional[Database] = None, validate: bool = True, ) -> typing.Sequence[MODEL_TV] This method will update all instance by sql case statement, example sql: UPDATE `user` SET `name` = CASE WHEN `id` = <id1> THEN <name1> WHEN `id` = <id2> THEN <name2> WHEN `id` = <id3> THEN <name3> end, WHERE `id` IN ( <id1>, <id2>, <id3>); And all instances will active model signals too. eg: users = await User.where().fetch_all() for u in users: u.name += \"_updated\" await User.bulk_update(users, fields=(User.name, )) Consider grouping instances and calling bulk_update in sequence if instances size is too large.","title":"Bulk Update"},{"location":"bulk_queries/#bulk-delete","text":"@classmethod async def bulk_delete( cls, instances: typing.Sequence[MODEL_TV], database: typing.Optional[Database] = None, ) -> int This method will delete all instance in database and return deleted count, example sql: DELETE FROM <table> WHERE `id` IN (<id1>, <id2>) And all instances will active model signals too.","title":"Bulk delete"},{"location":"bulk_queries/#upsert","text":"@classmethod async def upsert( cls, insert_data: typing.List[typing.Dict[str, typing.Any]], database: typing.Optional[Database] = None, update_fields: typing.Sequence[str] = (), conflict_targets: typing.Sequence[str] = (), ) -> typing.Tuple[bool, bool] This method using insert on duplicate, sql example for MySQL: INSERT INTO <table> (<f1>,<f2>) VALUES (<v1>,<v2>) ON DUPLICATE KEY UPDATE <f2>=VALUES(<f2>); And this method just execute a raw sql, eg: created, updated = await User.upsert( [ dict(id=1, name=\"updated\"), ], update_fields=[\"name\"], )","title":"Upsert"},{"location":"bulk_queries/#difference-between-databases","text":"For MySQL, updated means the table has been real updated(It will be False if update to original value), but MySQL will only update the first matched unique key if there are many matched conflict unique keys. For PostgreSQL, created and updated will always be true, need explicit conflict_targets . For SQLITE, updated will always be true. Documents: https://dev.mysql.com/doc/refman/5.6/en/insert-on-duplicate.html https://www.sqlite.org/lang_upsert.html https://www.postgresql.org/docs/9.4/plpgsql-control-structures.html#PLPGSQL-ERROR-TRAPPING","title":"Difference between Databases"},{"location":"combo_queries/","text":"Combo queries Get or Create async def get_or_create( self: MODEL_TV, key_fields: typing.Sequence[Field], database: typing.Optional[Database] = None, fields: typing.Sequence[Field] = (), validate: bool = True, for_update: bool = False, ) -> typing.Tuple[MODEL_TV, bool] This method will search and get a instance from database by key_fields (primary key or unique key fields) value, or create a new one if no data match. eg: async def get_one(): config, created = await Config(id=1, f=\"v\").get_or_create((Config.id,)) And the instance will active signals( *_read or *_update ) Create or Update async def create_or_update( self: MODEL_TV, key_fields: typing.Sequence[Field], database: typing.Optional[Database] = None, fields: typing.Sequence[Field] = (), update_fields: typing.Sequence[Field] = (), validate: bool = True, for_update: bool = True, ) -> typing.Tuple[MODEL_TV, bool, bool] This method will call get_or_create then update to database if database has matched data, all operation will wrap in one transaction, eg: async def subscribe(cls, user_id: int, blogger_id: int): ins, created, updated = await Sub(user_id=user_id, blogger_id=blogger_id, status=Sub.Status.SUBSCRIBED).create_or_update( (Sub.user_id, Sub.blogger_id), update_fields=(Sub.status,) ) if created or updated: await redis.incr(f\"BLOGGER_SUBSCRIBED_COUNT_{blogger_id}\") And the instance will active signals too.","title":"Combo Queries"},{"location":"combo_queries/#combo-queries","text":"","title":"Combo queries"},{"location":"combo_queries/#get-or-create","text":"async def get_or_create( self: MODEL_TV, key_fields: typing.Sequence[Field], database: typing.Optional[Database] = None, fields: typing.Sequence[Field] = (), validate: bool = True, for_update: bool = False, ) -> typing.Tuple[MODEL_TV, bool] This method will search and get a instance from database by key_fields (primary key or unique key fields) value, or create a new one if no data match. eg: async def get_one(): config, created = await Config(id=1, f=\"v\").get_or_create((Config.id,)) And the instance will active signals( *_read or *_update )","title":"Get or Create"},{"location":"combo_queries/#create-or-update","text":"async def create_or_update( self: MODEL_TV, key_fields: typing.Sequence[Field], database: typing.Optional[Database] = None, fields: typing.Sequence[Field] = (), update_fields: typing.Sequence[Field] = (), validate: bool = True, for_update: bool = True, ) -> typing.Tuple[MODEL_TV, bool, bool] This method will call get_or_create then update to database if database has matched data, all operation will wrap in one transaction, eg: async def subscribe(cls, user_id: int, blogger_id: int): ins, created, updated = await Sub(user_id=user_id, blogger_id=blogger_id, status=Sub.Status.SUBSCRIBED).create_or_update( (Sub.user_id, Sub.blogger_id), update_fields=(Sub.status,) ) if created or updated: await redis.incr(f\"BLOGGER_SUBSCRIBED_COUNT_{blogger_id}\") And the instance will active signals too.","title":"Create or Update"},{"location":"custom_field/","text":"Custom field It's easy to define a custom danio field, main code: @dataclasses.dataclass class Field: TYPE: typing.ClassVar[str] = \"\" name: str = \"\" model_name: str = \"\" default: typing.Any = NoDefault # for model layer type: str = \"\" primary: bool = False auto_increment: bool = False comment: str = \"\" enum: typing.Optional[typing.Type[enum.Enum]] = None def to_python(self, value: typing.Any) -> typing.Any: \"\"\"From databases raw data to python\"\"\" def to_database(self, value: typing.Any) -> typing.Any: \"\"\"From python to databases raw\"\"\" Custom default Type Danio will set field type to TYPE class var by default, eg: @dataclasses.dataclass class MyIntField(danio.IntField): TYPE = \"int(10)\" Custom raw type conversion Danio use Field.to_python and Field.to_database to convert field value type between model value and database value. Example Let's see danio.JsonField definition: @dataclasses.dataclass(eq=False) class JsonField(Field): TYPE: typing.ClassVar[str] = \"varchar(2048)\" default: typing.Any = dataclasses.field(default_factory=dict) def to_python(self, value: str) -> typing.Any: return json.loads(value) def to_database(self, value: typing.Any) -> str: return json.dumps(value)","title":"Custom Field"},{"location":"custom_field/#custom-field","text":"It's easy to define a custom danio field, main code: @dataclasses.dataclass class Field: TYPE: typing.ClassVar[str] = \"\" name: str = \"\" model_name: str = \"\" default: typing.Any = NoDefault # for model layer type: str = \"\" primary: bool = False auto_increment: bool = False comment: str = \"\" enum: typing.Optional[typing.Type[enum.Enum]] = None def to_python(self, value: typing.Any) -> typing.Any: \"\"\"From databases raw data to python\"\"\" def to_database(self, value: typing.Any) -> typing.Any: \"\"\"From python to databases raw\"\"\"","title":"Custom field"},{"location":"custom_field/#custom-default-type","text":"Danio will set field type to TYPE class var by default, eg: @dataclasses.dataclass class MyIntField(danio.IntField): TYPE = \"int(10)\"","title":"Custom default Type"},{"location":"custom_field/#custom-raw-type-conversion","text":"Danio use Field.to_python and Field.to_database to convert field value type between model value and database value.","title":"Custom raw type conversion"},{"location":"custom_field/#example","text":"Let's see danio.JsonField definition: @dataclasses.dataclass(eq=False) class JsonField(Field): TYPE: typing.ClassVar[str] = \"varchar(2048)\" default: typing.Any = dataclasses.field(default_factory=dict) def to_python(self, value: str) -> typing.Any: return json.loads(value) def to_database(self, value: typing.Any) -> str: return json.dumps(value)","title":"Example"},{"location":"make_queries/","text":"Make queries Danio making queries by model's instance method and class method. Base method There are basic instance method: create insert instance to database async def create( self: MODEL_TV, database: typing.Optional[Database] = None, fields: typing.Sequence[Field] = (), validate: bool = True, ) update update instance data to database async def update( self: MODEL_TV, database: typing.Optional[Database] = None, fields: typing.Sequence[Field] = (), validate: bool = True, ) -> bool save insert or update instance data to database async def save( self: MODEL_TV, database: typing.Optional[Database] = None, fields: typing.Sequence[Field] = (), force_insert=False, validate: bool = True, ) -> MODEL_TV refetch refetch instance data from database by primary key async def refetch( self: MODEL_TV, database: typing.Optional[Database] = None, fields: typing.Sequence[Field] = tuple(), ) -> MODEL_TV: delete async def delete( self, database: typing.Optional[Database] = None, ) -> bool eg: await Cat(name=\"dangdang\", age=5).create() await Cat(id=1, name=\"dangdang\", age=5).update() await Cat(name=\"dangdang\", age=5).save() # call create await Cat(id=1, name=\"dangdang\", age=5).save() # call update await Cat(id=1).delete() database and fields params All query method support database param, if not set danio will call cls.get_database to obtain one database instance.And we can pass a database with transaction, eg: db = Cat.get_database(danio.Operation.UPDATE, Cat.table_name) async with db.transaction(): cat = await Cat.where(Cat.id == 1, database=db).for_update().fetch_one() if cat: cat.name += \"_updated\" await cat.save() All query method with model layer(interact with model instance), support fields param, means only those fields will be select, insert or update, eg: cat = await Cat.where().fetch_one(fields=[Cat.name]) print(cat.id) # will be 0(default id value) await Cat(id=1, name=\"dangdang\", age=5).update(fields=[Cat.name]) # only name field will be update in database Where Chain Danio use where chain to express and execute basic SQL actually. @classmethod def where( cls: typing.Type[MODEL_TV], *conditions: SQLExpression, database: typing.Optional[Database] = None, fields: typing.Sequence[Field] = tuple(), raw=\"\", is_and=True, ) -> Crud[MODEL_TV] Read(Model layer) Get instance or raw data back from database: where().fetch_all - select all matched data and return a list of model instance where().fetch_one - select first matched data and return one model instance eg: cats = await Cat.where().fetch_all() await cats[-1].delete() cat = await Cat.where().fetch_one() await cat.delete() Other operation Except fetch_all , fetch_one , there are raw sql operation method(without model layer) for where chain: fetch_count - select count async def fetch_count(self) -> int fetch_row - fetch row data from database async def fetch_row(self, fields: typing.Sequence[Field] = tuple()) -> typing.List[typing.Mapping] update - update data by condition without model layer async def update(self, **data) -> int delete - without model layer too async def delete(self) -> int for_update - select with UPDATE lock def for_update(self: CRUD_TV) -> CRUD_TV for_select - select with SHARE lock def for_select(self: CRUD_TV) -> CRUD_TV use_index - select with index hints def use_index(self: CRUD_TV, indexes: typing.Sequence[str], _for: str = \"\") -> CRUD_TV force_index - select with index hints def force_index(self: CRUD_TV, indexes: typing.Sequence[str], _for: str = \"\") -> CRUD_TV ignore_index - select with index hints def ignore_index(self: CRUD_TV, indexes: typing.Sequence[str], _for: str = \"\") -> CRUD_TV limit def limit(self, n: int) -> Crud offset def offset(self, n: int) -> Crud order_by def order_by(self, f: typing.Union[Field, SQLExpression], asc=True) -> Crud eg: await Cat.where().delete() count = await Cat.where().fetch_count() print(count) # will be 0 await Cat.where().update(name=\"all_updated\") eg: await Cat.where().offset(20).limit(10).fetch_all() await Cat.where().order_by(Cat.name, asc=False).fetch_all() await Cat.where().for_update().fetch_all() await Cat.where().for_share().fetch_all() Where Condition Danio overwrite field class's some magic method like __eq__ , __gt__ and other else for simplify express sql condition. def __eq__(self, other: typing.Any) -> SQLExpression: # type: ignore[override] ... ... eg: await Cat.where(Cat.id == 1).delete() await Cat.where(Cat.id == 1).fetch_one() await Cat.where(Cat.name == \"old\").update(name=\"new\") Danio support simple expressions for now: == \">\" \">=\" < <= != Danio also support sql like and contain condition, eg: await Cat.where(Cat.id.contains([1, 2, 3])).fetch_all() await Cat.where(Cat.name.like(\"%name%\")).fetch_all() # for char/text field only Danio also support complicated expression: await Cat.where((Cat.id + 1) > u.id).fetch_one() ## `id` + 1 > 1 await Cat.where((Cat.id < 10) | (Cat.id > 20)).fetch_one() ## id < 10 or id > 20 And we can combine multiple condition by where chain , eg: await Cat.where(Cat.id > 10, Cat.id < 20).fetch_all() # 10 < id < 20 await Cat.where(Cat.id > 10).where(Cat.id < 20).fetch_all() # 10 < id < 20 await Cat.where(Cat.id < 10).where(Cat.id > 20, is_and=False).fetch_all() # id < 10 or id > 20","title":"Make Queries"},{"location":"make_queries/#make-queries","text":"Danio making queries by model's instance method and class method.","title":"Make queries"},{"location":"make_queries/#base-method","text":"There are basic instance method:","title":"Base method"},{"location":"make_queries/#create","text":"insert instance to database async def create( self: MODEL_TV, database: typing.Optional[Database] = None, fields: typing.Sequence[Field] = (), validate: bool = True, )","title":"create"},{"location":"make_queries/#update","text":"update instance data to database async def update( self: MODEL_TV, database: typing.Optional[Database] = None, fields: typing.Sequence[Field] = (), validate: bool = True, ) -> bool","title":"update"},{"location":"make_queries/#save","text":"insert or update instance data to database async def save( self: MODEL_TV, database: typing.Optional[Database] = None, fields: typing.Sequence[Field] = (), force_insert=False, validate: bool = True, ) -> MODEL_TV","title":"save"},{"location":"make_queries/#refetch","text":"refetch instance data from database by primary key async def refetch( self: MODEL_TV, database: typing.Optional[Database] = None, fields: typing.Sequence[Field] = tuple(), ) -> MODEL_TV:","title":"refetch"},{"location":"make_queries/#delete","text":"async def delete( self, database: typing.Optional[Database] = None, ) -> bool eg: await Cat(name=\"dangdang\", age=5).create() await Cat(id=1, name=\"dangdang\", age=5).update() await Cat(name=\"dangdang\", age=5).save() # call create await Cat(id=1, name=\"dangdang\", age=5).save() # call update await Cat(id=1).delete()","title":"delete"},{"location":"make_queries/#database-and-fields-params","text":"All query method support database param, if not set danio will call cls.get_database to obtain one database instance.And we can pass a database with transaction, eg: db = Cat.get_database(danio.Operation.UPDATE, Cat.table_name) async with db.transaction(): cat = await Cat.where(Cat.id == 1, database=db).for_update().fetch_one() if cat: cat.name += \"_updated\" await cat.save() All query method with model layer(interact with model instance), support fields param, means only those fields will be select, insert or update, eg: cat = await Cat.where().fetch_one(fields=[Cat.name]) print(cat.id) # will be 0(default id value) await Cat(id=1, name=\"dangdang\", age=5).update(fields=[Cat.name]) # only name field will be update in database","title":"database and fields params"},{"location":"make_queries/#where-chain","text":"Danio use where chain to express and execute basic SQL actually. @classmethod def where( cls: typing.Type[MODEL_TV], *conditions: SQLExpression, database: typing.Optional[Database] = None, fields: typing.Sequence[Field] = tuple(), raw=\"\", is_and=True, ) -> Crud[MODEL_TV]","title":"Where Chain"},{"location":"make_queries/#readmodel-layer","text":"Get instance or raw data back from database: where().fetch_all - select all matched data and return a list of model instance where().fetch_one - select first matched data and return one model instance eg: cats = await Cat.where().fetch_all() await cats[-1].delete() cat = await Cat.where().fetch_one() await cat.delete()","title":"Read(Model layer)"},{"location":"make_queries/#other-operation","text":"Except fetch_all , fetch_one , there are raw sql operation method(without model layer) for where chain: fetch_count - select count async def fetch_count(self) -> int fetch_row - fetch row data from database async def fetch_row(self, fields: typing.Sequence[Field] = tuple()) -> typing.List[typing.Mapping] update - update data by condition without model layer async def update(self, **data) -> int delete - without model layer too async def delete(self) -> int for_update - select with UPDATE lock def for_update(self: CRUD_TV) -> CRUD_TV for_select - select with SHARE lock def for_select(self: CRUD_TV) -> CRUD_TV use_index - select with index hints def use_index(self: CRUD_TV, indexes: typing.Sequence[str], _for: str = \"\") -> CRUD_TV force_index - select with index hints def force_index(self: CRUD_TV, indexes: typing.Sequence[str], _for: str = \"\") -> CRUD_TV ignore_index - select with index hints def ignore_index(self: CRUD_TV, indexes: typing.Sequence[str], _for: str = \"\") -> CRUD_TV limit def limit(self, n: int) -> Crud offset def offset(self, n: int) -> Crud order_by def order_by(self, f: typing.Union[Field, SQLExpression], asc=True) -> Crud eg: await Cat.where().delete() count = await Cat.where().fetch_count() print(count) # will be 0 await Cat.where().update(name=\"all_updated\") eg: await Cat.where().offset(20).limit(10).fetch_all() await Cat.where().order_by(Cat.name, asc=False).fetch_all() await Cat.where().for_update().fetch_all() await Cat.where().for_share().fetch_all()","title":"Other operation"},{"location":"make_queries/#where-condition","text":"Danio overwrite field class's some magic method like __eq__ , __gt__ and other else for simplify express sql condition. def __eq__(self, other: typing.Any) -> SQLExpression: # type: ignore[override] ... ... eg: await Cat.where(Cat.id == 1).delete() await Cat.where(Cat.id == 1).fetch_one() await Cat.where(Cat.name == \"old\").update(name=\"new\") Danio support simple expressions for now: == \">\" \">=\" < <= != Danio also support sql like and contain condition, eg: await Cat.where(Cat.id.contains([1, 2, 3])).fetch_all() await Cat.where(Cat.name.like(\"%name%\")).fetch_all() # for char/text field only Danio also support complicated expression: await Cat.where((Cat.id + 1) > u.id).fetch_one() ## `id` + 1 > 1 await Cat.where((Cat.id < 10) | (Cat.id > 20)).fetch_one() ## id < 10 or id > 20 And we can combine multiple condition by where chain , eg: await Cat.where(Cat.id > 10, Cat.id < 20).fetch_all() # 10 < id < 20 await Cat.where(Cat.id > 10).where(Cat.id < 20).fetch_all() # 10 < id < 20 await Cat.where(Cat.id < 10).where(Cat.id > 20, is_and=False).fetch_all() # id < 10 or id > 20","title":"Where Condition"},{"location":"model_definition/","text":"Define Model Danio use python's dataclasses as model layer.A danio model is basically a dataclass instance with special method and variable. Field Danio use danio.field function to define a field in model def field( field_cls=Field, type=\"\", name=\"\", comment=\"\", default=Field.FieldDefault, primary=False, auto_increment=False, not_null=True, enum: typing.Optional[typing.Type[enum.Enum]] = None, ) -> typing.Any eg: import danio @dataclasses.dataclass class Cat(danio.Model): id: int = danio.field(IntField, primary=True, auto_increment=True) name: str = danio.field(danio.CharField, comment=\"cat name\") age: int = danio.field(danio.IntField) There are the corresponding database table schema: CREATE TABLE `cat` ( `id` int NOT NULL AUTO_INCREMENT COMMENT '', `name` varchar(255) NOT NULL COMMENT 'cat name', `age` int NOT NULL COMMENT '', PRIMARY KEY (`id`), ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;; We can define more detail by danio.field params: Define a different name in database: name: str = danio.filed(danio.ChareField, name=\"name_in_database\") Define a custom type: name: str = danio.filed(danio.ChareField, type=\"varchar(16)\") Define default value(Only affect model layer, will not set database field default'): age: int = danio.field(danio.IntField, default=1) Define auto increment: id: int = danio.field(danio.IntField, auto_increment=True) Define enum class(Only affect model layer, danio will load database value to defined enum): gender: Gender = danio.field(danio.IntField, enum=Gender, default=Gender.FEMALE) Danio provide fields for now(It's easy to define custom field too): TinyField, SmallIntField, IntField, BigIntField BoolField(actually use tinyint in database by default), FloatField, DecimalField CharField, TextField TimeField, DateField, DateTimeField JsonField(actually use varchar in database by default) By typing.Annotated ( Required in python3.11 ) eg: import typing import dataclasses import danio @dataclasses.dataclass class Cat(danio.Model): id: typing.Annotated[int, danio.IntField(primary=True, auto_increment=True)] = 0 name: typing.Annotated[int, danio.CharField(comment=\"cat name\")] = 0 age: typing.Annotated[int, danio.IntField] = 0 Class Attribute and Instance Attribute By dataclasses we can access model field by class attribute, eg: user = User() User.id # IntField(...) user.id # 1 and danio will also generate a upcase class atrribute for distinguish with instance atrribute, eg: User.ID # IntField(...) User.ID == User.id # True event more, you can use danio to auto write model type hints in code, like: await danio.manage.write_model_hints(database, User) Then the user model file will be updated like: class User(danio.Model): # --------------------Danio Hints-------------------- # TABLE NAME: user # TABLE IS MIGRATED! ID: typing.ClassVar[danio.Field] # \"id\" serial PRIMARY KEY NOT NULL NAME: typing.ClassVar[danio.Field] # \"name\" varchar(255) NOT NULL AGE: typing.ClassVar[danio.Field] # \"age\" int NOT NULL CREATED_AT: typing.ClassVar[ danio.Field ] # \"created_at\" timestamp without time zone NOT NULL UPDATED_AT: typing.ClassVar[ danio.Field ] # \"updated_at\" timestamp without time zone NOT NULL GENDER: typing.ClassVar[danio.Field] # \"gender\" int NOT NULL # --------------------Danio Hints-------------------- class Gender(enum.Enum): MALE = 0 FEMALE = 1 OTHER = 2 id: typing.Annotated[int, danio.IntField(primary=True, type=\"serial\")] = 0 name: typing.Annotated[str, danio.CharField(comment=\"User name\")] = \"\" age: typing.Annotated[int, danio.IntField] = 0 ... Index Danio store index information in model's classvar _table_*_keys , eg: @dataclasses.dataclass class UserProfile(danio.Model): user_id: int = danio.field(danio.IntField) level: int = danio.field(danio.IntField) _table_index_keys: typing.ClassVar[ typing.Tuple[typing.Tuple[typing.Union[Field, str], ...], ...] ] = ((level, user_id,),) _table_unique_keys: typing.ClassVar[ typing.Tuple[typing.Tuple[typing.Union[Field, str], ...], ...] ] = ((\"user_id\",),) or @dataclasses.dataclass class UserProfile(danio.Model): user_id: typing.Annotated[int, danio.IntField] = 0 level: typing.Annotated[int, danio.IntField] = 0 @classmethod def get_index_keys(cls) -> typing.Tuple[typing.Tuple[typing.Union[Field, str], ...], ...]: return ((level, user_id,),) @classmethod def get_unique_keys(cls) -> typing.Tuple[typing.Tuple[typing.Union[Field, str], ...], ...]: return ((\"user_id\",),) There are the corresponding database table schema: ... UNIQUE KEY `user_id_471_uiq` (`user_id`), KEY `level_user_id_231_idx` (`level`, `user_id`) ... Model Inherit Danio use dataclasses's way to inherit, we can define a base model first: @dataclasses.dataclass class Pet(danio.Model): name: str = danio.field(danio.CharField) age: int = danio.field(danio.IntField) _table_abstracted: typing.ClassVar[bool] = True _table_index_keys = ((age,),) _table_abstracted=True means no pet table in database. Then we inherit Pet: @dataclasses.dataclass class Cat(Pet): weight: int = danio.field(danio.IntField) So Cat has 4 field now: id, name, age and weight .We can disable or redefine a field: @dataclasses.dataclass class Dog(Pet): name: str = \"\" age: int = danio.field(danio.SmallIntField) Now Cat got 3 fields: id, age, weight .We can still use name variable as a normal dataclass's variable.And all Cat and Dog got same one index by field age.We can change this index too: @dataclasses.dataclass class Fish(Pet): _table_index_keys = ((Pet.name,),) Or add new one to the original index: @dataclasses.dataclass class Fish(Pet): _table_index_keys = Pet._table_index_keys + ((Pet.name,),) Config database Table name Danio obtain model schema's table name by get_table_name method, just join table prefix and model name by default: @classmethod def get_table_name(cls) -> str: return cls._table_name_prefix + cls.__name__.lower() Database For model's database instance, defined by get_database method: def get_database( cls, operation: Operation, table: str, *args, **kwargs ) -> Database We can define this at a base model: db = danio.Database( \"mysql://root:letmein@server:3306/test\", maxsize=3, charset=\"utf8mb4\", use_unicode=True, connect_timeout=60, ) @dataclasses.dataclass class BaseModel(danio.Model): @classmethod def get_database( cls, operation: danio.Operation, table: str, *args, **kwargs ) -> danio.Database: return db Now any model inherit BaseModel will get db as database. And we can set more than one database instance: # read_db = ... # config_db = ... # write_db = ... @classmethod def get_database( cls, operation: danio.Operation, table: str, *args, **kwargs ) -> danio.Database: if operation == danio.Operation.READ: return read_db elif table.startswith(\"config_\"): return config_db else: return write_db","title":"Model Definition"},{"location":"model_definition/#define-model","text":"Danio use python's dataclasses as model layer.A danio model is basically a dataclass instance with special method and variable.","title":"Define Model"},{"location":"model_definition/#field","text":"Danio use danio.field function to define a field in model def field( field_cls=Field, type=\"\", name=\"\", comment=\"\", default=Field.FieldDefault, primary=False, auto_increment=False, not_null=True, enum: typing.Optional[typing.Type[enum.Enum]] = None, ) -> typing.Any eg: import danio @dataclasses.dataclass class Cat(danio.Model): id: int = danio.field(IntField, primary=True, auto_increment=True) name: str = danio.field(danio.CharField, comment=\"cat name\") age: int = danio.field(danio.IntField) There are the corresponding database table schema: CREATE TABLE `cat` ( `id` int NOT NULL AUTO_INCREMENT COMMENT '', `name` varchar(255) NOT NULL COMMENT 'cat name', `age` int NOT NULL COMMENT '', PRIMARY KEY (`id`), ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;; We can define more detail by danio.field params: Define a different name in database: name: str = danio.filed(danio.ChareField, name=\"name_in_database\") Define a custom type: name: str = danio.filed(danio.ChareField, type=\"varchar(16)\") Define default value(Only affect model layer, will not set database field default'): age: int = danio.field(danio.IntField, default=1) Define auto increment: id: int = danio.field(danio.IntField, auto_increment=True) Define enum class(Only affect model layer, danio will load database value to defined enum): gender: Gender = danio.field(danio.IntField, enum=Gender, default=Gender.FEMALE) Danio provide fields for now(It's easy to define custom field too): TinyField, SmallIntField, IntField, BigIntField BoolField(actually use tinyint in database by default), FloatField, DecimalField CharField, TextField TimeField, DateField, DateTimeField JsonField(actually use varchar in database by default)","title":"Field"},{"location":"model_definition/#by-typingannotatedrequired-in-python311","text":"eg: import typing import dataclasses import danio @dataclasses.dataclass class Cat(danio.Model): id: typing.Annotated[int, danio.IntField(primary=True, auto_increment=True)] = 0 name: typing.Annotated[int, danio.CharField(comment=\"cat name\")] = 0 age: typing.Annotated[int, danio.IntField] = 0","title":"By typing.Annotated(Required in python3.11)"},{"location":"model_definition/#class-attribute-and-instance-attribute","text":"By dataclasses we can access model field by class attribute, eg: user = User() User.id # IntField(...) user.id # 1 and danio will also generate a upcase class atrribute for distinguish with instance atrribute, eg: User.ID # IntField(...) User.ID == User.id # True event more, you can use danio to auto write model type hints in code, like: await danio.manage.write_model_hints(database, User) Then the user model file will be updated like: class User(danio.Model): # --------------------Danio Hints-------------------- # TABLE NAME: user # TABLE IS MIGRATED! ID: typing.ClassVar[danio.Field] # \"id\" serial PRIMARY KEY NOT NULL NAME: typing.ClassVar[danio.Field] # \"name\" varchar(255) NOT NULL AGE: typing.ClassVar[danio.Field] # \"age\" int NOT NULL CREATED_AT: typing.ClassVar[ danio.Field ] # \"created_at\" timestamp without time zone NOT NULL UPDATED_AT: typing.ClassVar[ danio.Field ] # \"updated_at\" timestamp without time zone NOT NULL GENDER: typing.ClassVar[danio.Field] # \"gender\" int NOT NULL # --------------------Danio Hints-------------------- class Gender(enum.Enum): MALE = 0 FEMALE = 1 OTHER = 2 id: typing.Annotated[int, danio.IntField(primary=True, type=\"serial\")] = 0 name: typing.Annotated[str, danio.CharField(comment=\"User name\")] = \"\" age: typing.Annotated[int, danio.IntField] = 0 ...","title":"Class Attribute and Instance Attribute"},{"location":"model_definition/#index","text":"Danio store index information in model's classvar _table_*_keys , eg: @dataclasses.dataclass class UserProfile(danio.Model): user_id: int = danio.field(danio.IntField) level: int = danio.field(danio.IntField) _table_index_keys: typing.ClassVar[ typing.Tuple[typing.Tuple[typing.Union[Field, str], ...], ...] ] = ((level, user_id,),) _table_unique_keys: typing.ClassVar[ typing.Tuple[typing.Tuple[typing.Union[Field, str], ...], ...] ] = ((\"user_id\",),) or @dataclasses.dataclass class UserProfile(danio.Model): user_id: typing.Annotated[int, danio.IntField] = 0 level: typing.Annotated[int, danio.IntField] = 0 @classmethod def get_index_keys(cls) -> typing.Tuple[typing.Tuple[typing.Union[Field, str], ...], ...]: return ((level, user_id,),) @classmethod def get_unique_keys(cls) -> typing.Tuple[typing.Tuple[typing.Union[Field, str], ...], ...]: return ((\"user_id\",),) There are the corresponding database table schema: ... UNIQUE KEY `user_id_471_uiq` (`user_id`), KEY `level_user_id_231_idx` (`level`, `user_id`) ...","title":"Index"},{"location":"model_definition/#model-inherit","text":"Danio use dataclasses's way to inherit, we can define a base model first: @dataclasses.dataclass class Pet(danio.Model): name: str = danio.field(danio.CharField) age: int = danio.field(danio.IntField) _table_abstracted: typing.ClassVar[bool] = True _table_index_keys = ((age,),) _table_abstracted=True means no pet table in database. Then we inherit Pet: @dataclasses.dataclass class Cat(Pet): weight: int = danio.field(danio.IntField) So Cat has 4 field now: id, name, age and weight .We can disable or redefine a field: @dataclasses.dataclass class Dog(Pet): name: str = \"\" age: int = danio.field(danio.SmallIntField) Now Cat got 3 fields: id, age, weight .We can still use name variable as a normal dataclass's variable.And all Cat and Dog got same one index by field age.We can change this index too: @dataclasses.dataclass class Fish(Pet): _table_index_keys = ((Pet.name,),) Or add new one to the original index: @dataclasses.dataclass class Fish(Pet): _table_index_keys = Pet._table_index_keys + ((Pet.name,),)","title":"Model Inherit"},{"location":"model_definition/#config-database","text":"","title":"Config database"},{"location":"model_definition/#table-name","text":"Danio obtain model schema's table name by get_table_name method, just join table prefix and model name by default: @classmethod def get_table_name(cls) -> str: return cls._table_name_prefix + cls.__name__.lower()","title":"Table name"},{"location":"model_definition/#database","text":"For model's database instance, defined by get_database method: def get_database( cls, operation: Operation, table: str, *args, **kwargs ) -> Database We can define this at a base model: db = danio.Database( \"mysql://root:letmein@server:3306/test\", maxsize=3, charset=\"utf8mb4\", use_unicode=True, connect_timeout=60, ) @dataclasses.dataclass class BaseModel(danio.Model): @classmethod def get_database( cls, operation: danio.Operation, table: str, *args, **kwargs ) -> danio.Database: return db Now any model inherit BaseModel will get db as database. And we can set more than one database instance: # read_db = ... # config_db = ... # write_db = ... @classmethod def get_database( cls, operation: danio.Operation, table: str, *args, **kwargs ) -> danio.Database: if operation == danio.Operation.READ: return read_db elif table.startswith(\"config_\"): return config_db else: return write_db","title":"Database"},{"location":"model_migration/","text":"Model Migration Danio's provide a simple way to support model migration. Get Migration SQL danio.manage.make_migration : async def make_migration( db: Database, models: typing.Sequence[typing.Type[Model]], dir: str ) -> str This function will compare the table schema between passed models and current database , then write 2 migration sql file( _up.sql, _down.sql) to dir directory. Support migrate action for now: add new table add/drop field modify field type add/drop table index The example migration sql file(change field data type from TEXT to VARCHAR(255) ): 2022_02_28_08_43_00_up.sql: USE `test`; ALTER TABLE `log` MODIFY `data` VARCHAR(255); 2022_02_28_08_43_00_down.sql: USE `test`; ALTER TABLE `log` MODIFY `data` TEXT; Get Code Models danio.manage.get_models : def get_models(paths: typing.List[str]) -> typing.List[typing.Type[Model]] This function will find and return all model except abstracted.","title":"Model Migration"},{"location":"model_migration/#model-migration","text":"Danio's provide a simple way to support model migration.","title":"Model Migration"},{"location":"model_migration/#get-migration-sql","text":"danio.manage.make_migration : async def make_migration( db: Database, models: typing.Sequence[typing.Type[Model]], dir: str ) -> str This function will compare the table schema between passed models and current database , then write 2 migration sql file( _up.sql, _down.sql) to dir directory. Support migrate action for now: add new table add/drop field modify field type add/drop table index The example migration sql file(change field data type from TEXT to VARCHAR(255) ): 2022_02_28_08_43_00_up.sql: USE `test`; ALTER TABLE `log` MODIFY `data` VARCHAR(255); 2022_02_28_08_43_00_down.sql: USE `test`; ALTER TABLE `log` MODIFY `data` TEXT;","title":"Get Migration SQL"},{"location":"model_migration/#get-code-models","text":"danio.manage.get_models : def get_models(paths: typing.List[str]) -> typing.List[typing.Type[Model]] This function will find and return all model except abstracted.","title":"Get Code Models"},{"location":"model_signal/","text":"Signal Danio support signal during instance's life cycle, all sql operation interact with model instance (receive or return instance as param) will call those signal method: after_read - called after the instance has been read from database async def after_read(self) -> None before_create - called before the instance has been created to database after_create - called after the instance has been created to database before_update after_update before_delete after_delete Special signal: after_init - called after the instance has been init (call by __post_init__ actually) def after_init(self) -> None eg: count = 0 @dataclasses.dataclass class Pet(danio.Model): name: str = danio.field(danio.CharField) age: int = danio.field(danio.IntField) code: str = \"\" def after_init(self): super().after_init() self.code = f\"{self.name}_{self.age}\" async def after_create(self): await super().after_create() count += 1 async def after_delete(self): await super().after_delete() count -= 1","title":"Model Signal"},{"location":"model_signal/#signal","text":"Danio support signal during instance's life cycle, all sql operation interact with model instance (receive or return instance as param) will call those signal method: after_read - called after the instance has been read from database async def after_read(self) -> None before_create - called before the instance has been created to database after_create - called after the instance has been created to database before_update after_update before_delete after_delete Special signal: after_init - called after the instance has been init (call by __post_init__ actually) def after_init(self) -> None eg: count = 0 @dataclasses.dataclass class Pet(danio.Model): name: str = danio.field(danio.CharField) age: int = danio.field(danio.IntField) code: str = \"\" def after_init(self): super().after_init() self.code = f\"{self.name}_{self.age}\" async def after_create(self): await super().after_create() count += 1 async def after_delete(self): await super().after_delete() count -= 1","title":"Signal"},{"location":"postgresql/","text":"PostgreSQL Danio support PostgreSQL with a little code change. Database Define Use asyncpg driver: db = danio.Database( f\"postgres://postgres:{os.getenv('POSTGRES_PASSWORD', 'letmein')}@{os.getenv('POSTGRES_HOST', 'postgres')}:5432/{db_name}\", min_size=1, max_size=3, max_inactive_connection_lifetime=60, ) Use aiopg driver: db2 = danio.Database( f\"aiopg://postgres:{os.getenv('POSTGRES_PASSWORD', 'letmein')}@{os.getenv('POSTGRES_HOST', 'postgres')}:5432/{db_name}\", min_size=1, max_size=3, ) Auto Increment Field Danio use PostgreSQL's serial type as a auto increment field, so we should change Model's primary field define: @dataclasses.dataclass class BasePostgreSQLModel(danio.Model): id: int = danio.field(danio.IntField, primary=True, type=\"serial\", comment=\"primary key\") Field Type For PostgreSQL we may need change danio's field type define, like timestamp : updated_at: datetime.datetime = danio.field( danio.DateTimeField, type=\"timestamp without time zone\", comment=\"when created\", ) upsert PostgreSQL need explicit conflict_targets for upsert method","title":"PostgreSQL"},{"location":"postgresql/#postgresql","text":"Danio support PostgreSQL with a little code change.","title":"PostgreSQL"},{"location":"postgresql/#database-define","text":"Use asyncpg driver: db = danio.Database( f\"postgres://postgres:{os.getenv('POSTGRES_PASSWORD', 'letmein')}@{os.getenv('POSTGRES_HOST', 'postgres')}:5432/{db_name}\", min_size=1, max_size=3, max_inactive_connection_lifetime=60, ) Use aiopg driver: db2 = danio.Database( f\"aiopg://postgres:{os.getenv('POSTGRES_PASSWORD', 'letmein')}@{os.getenv('POSTGRES_HOST', 'postgres')}:5432/{db_name}\", min_size=1, max_size=3, )","title":"Database Define"},{"location":"postgresql/#auto-increment-field","text":"Danio use PostgreSQL's serial type as a auto increment field, so we should change Model's primary field define: @dataclasses.dataclass class BasePostgreSQLModel(danio.Model): id: int = danio.field(danio.IntField, primary=True, type=\"serial\", comment=\"primary key\")","title":"Auto Increment Field"},{"location":"postgresql/#field-type","text":"For PostgreSQL we may need change danio's field type define, like timestamp : updated_at: datetime.datetime = danio.field( danio.DateTimeField, type=\"timestamp without time zone\", comment=\"when created\", )","title":"Field Type"},{"location":"postgresql/#upsert","text":"PostgreSQL need explicit conflict_targets for upsert method","title":"upsert"},{"location":"sql_injection/","text":"SQL Injection Danio use databases 's way(actually sqlarchemy 's bindparams ) to avoid SQL Injection.All passed param will be escaped. SQLMarker SQLMarker is the base class to generate raw SQL.The mark method will create a placeholder for SQL value binding: class SQLMarker: class ID: def __init__(self, value: int = 0) -> None: ... def get_add(self) -> int: ... field: typing.Optional[Field] = None _var_index: ID = dataclasses.field(default_factory=ID) _vars: typing.Dict[str, typing.Any] = dataclasses.field(default_factory=dict) def mark(self, value: typing.Any) -> str: ... eg: print(f\"INSERT INTO HighScores(name, score) VALUES (:{self.mark(name)}, :{self.mark(score)})) # print \"INSERT INTO HighScores(name, score) VALUES (:var0, :var1)\" print(self._vars) # {\"var0\": \"name\", \"var1\": 1} Then pass SQL and all vars to database's execute await database.execute(sql, self._vars)","title":"SQL Injection"},{"location":"sql_injection/#sql-injection","text":"Danio use databases 's way(actually sqlarchemy 's bindparams ) to avoid SQL Injection.All passed param will be escaped.","title":"SQL Injection"},{"location":"sql_injection/#sqlmarker","text":"SQLMarker is the base class to generate raw SQL.The mark method will create a placeholder for SQL value binding: class SQLMarker: class ID: def __init__(self, value: int = 0) -> None: ... def get_add(self) -> int: ... field: typing.Optional[Field] = None _var_index: ID = dataclasses.field(default_factory=ID) _vars: typing.Dict[str, typing.Any] = dataclasses.field(default_factory=dict) def mark(self, value: typing.Any) -> str: ... eg: print(f\"INSERT INTO HighScores(name, score) VALUES (:{self.mark(name)}, :{self.mark(score)})) # print \"INSERT INTO HighScores(name, score) VALUES (:var0, :var1)\" print(self._vars) # {\"var0\": \"name\", \"var1\": 1} Then pass SQL and all vars to database's execute await database.execute(sql, self._vars)","title":"SQLMarker"},{"location":"sqlite/","text":"SQLite Database Define db = danio.Database(\"sqlite://test.db\") Primary Field We may need change danio's field type define to INTEGER for primary field: @dataclasses.dataclass class BaseSQLiteModel(danio.Model): id: int = danio.field( danio.IntField, primary=True, auto_increment=True, type=\"INTEGER\" ) For Update/Share SQLite do not support for update and for share lock.","title":"SQLite"},{"location":"sqlite/#sqlite","text":"","title":"SQLite"},{"location":"sqlite/#database-define","text":"db = danio.Database(\"sqlite://test.db\")","title":"Database Define"},{"location":"sqlite/#primary-field","text":"We may need change danio's field type define to INTEGER for primary field: @dataclasses.dataclass class BaseSQLiteModel(danio.Model): id: int = danio.field( danio.IntField, primary=True, auto_increment=True, type=\"INTEGER\" )","title":"Primary Field"},{"location":"sqlite/#for-updateshare","text":"SQLite do not support for update and for share lock.","title":"For Update/Share"},{"location":"tips/","text":"Tips There are some tips around danio. JSON Thanks orjson , we can covert danio model instance to json str with one line code: orjson.dumps(Cat(name=\"cc\")) Update? For update , create_or_update and upset will return a updated variable: updated = await Cat(id=3, name=\"new name\").update() cat, created, updated = await Cat(id=3, name=\"new name\").create_update((Cat.id, )) created, updated = await Cat.upsert( [ dict(id=3, name=\"new name\"), ], update_fields=[\"name\"], ) For MySQL, updated will be False if row data is same as incoming update data, but SQLite will return True in this case.","title":"Tips"},{"location":"tips/#tips","text":"There are some tips around danio.","title":"Tips"},{"location":"tips/#json","text":"Thanks orjson , we can covert danio model instance to json str with one line code: orjson.dumps(Cat(name=\"cc\"))","title":"JSON"},{"location":"tips/#update","text":"For update , create_or_update and upset will return a updated variable: updated = await Cat(id=3, name=\"new name\").update() cat, created, updated = await Cat(id=3, name=\"new name\").create_update((Cat.id, )) created, updated = await Cat.upsert( [ dict(id=3, name=\"new name\"), ], update_fields=[\"name\"], ) For MySQL, updated will be False if row data is same as incoming update data, but SQLite will return True in this case.","title":"Update?"}]}